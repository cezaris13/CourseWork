{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from Code.VQLSSVM import VQLSSVM\n",
    "from Code.Utils import prepareDataset\n",
    "\n",
    "np.set_printoptions(precision=10, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "qubits = 3\n",
    "shots: int = 10000\n",
    "gamma: float = 0.01 # regularization parameter\n",
    "subsetSize: int = 2**qubits - 1 # number of training points\n",
    "classToFilterOut: int = 2\n",
    "iterations = 5\n",
    "trainIterations = 200\n",
    "# datasets = [\"iris\"]\n",
    "datasets = [\"iris\",\"breastCancer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vqlssvmVectors: VQLSSVM = VQLSSVM(gamma, shots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getListsAverage(data: list):\n",
    "    maximumLengthList = len(max(data, key=len))\n",
    "    sumList =[]\n",
    "    for i in range(maximumLengthList):\n",
    "        iterationSum = 0\n",
    "        for j in range(len(data)):\n",
    "            if i < len(data[j]):\n",
    "                iterationSum += data[j][i]\n",
    "            else:\n",
    "                iterationSum += data[j][-1]\n",
    "        sumList.append(iterationSum)\n",
    "\n",
    "    sumList = np.array(sumList)\n",
    "    return sumList/len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 th iteration\n",
      "Dataset: iris\n",
      "Transpiled circuits length: 666\n",
      "Transpiled special circuits: 36\n",
      "Iteration: 98 , cost: 0.00589171593790160916\n",
      "\n",
      "Dataset: breastCancer\n",
      "Transpiled circuits length: 666\n",
      "Transpiled special circuits: 36\n",
      "Iteration: 90 , cost: 0.0939207446848501244\n",
      "\n",
      "\n",
      "\n",
      "1 th iteration\n",
      "Dataset: iris\n",
      "Transpiled circuits length: 666\n",
      "Transpiled special circuits: 36\n",
      "Iteration: 94 , cost: 0.01621468402760617445\n",
      "\n",
      "Dataset: breastCancer\n",
      "Transpiled circuits length: 666\n",
      "Transpiled special circuits: 36\n",
      "Iteration: 104 , cost: 0.05019346166892602\n",
      "\n",
      "\n",
      "\n",
      "2 th iteration\n",
      "Dataset: iris\n",
      "Transpiled circuits length: 666\n",
      "Transpiled special circuits: 36\n",
      "Iteration: 92 , cost: 0.041029461244190684\n",
      "\n",
      "Dataset: breastCancer\n",
      "Transpiled circuits length: 666\n",
      "Transpiled special circuits: 36\n",
      "Iteration: 108 , cost: 0.0075926248905318076\n",
      "\n",
      "\n",
      "\n",
      "3 th iteration\n",
      "Dataset: iris\n",
      "Transpiled circuits length: 666\n",
      "Transpiled special circuits: 36\n",
      "Iteration: 103 , cost: 0.0230233500377182796\n",
      "\n",
      "Dataset: breastCancer\n",
      "Transpiled circuits length: 666\n",
      "Transpiled special circuits: 36\n",
      "Iteration: 106 , cost: 0.0181492651184983485\n",
      "\n",
      "\n",
      "\n",
      "4 th iteration\n",
      "Dataset: iris\n",
      "Transpiled circuits length: 666\n",
      "Transpiled special circuits: 36\n",
      "Iteration: 97 , cost: 0.01233432266584200141\n",
      "\n",
      "Dataset: breastCancer\n",
      "Transpiled circuits length: 666\n",
      "Transpiled special circuits: 36\n",
      "Iteration: 98 , cost: 0.13111272939435192\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def collectTrainData(dataset: str, isQuantumSimulation: bool):\n",
    "    xTrain, xTest, yTrain, yTest = prepareDataset(normalizeValues=True, dataset=dataset,subsetSize=subsetSize, classToFilterOut=classToFilterOut)\n",
    "    vqlssvmVectors.train(xTrain, yTrain, quantumSimulation=isQuantumSimulation, verbose=False, iterations = trainIterations, method=\"COBYLA\", threads=4, jobs=4)\n",
    "    cost = vqlssvmVectors.getCostHistory()\n",
    "    accuracy = vqlssvmVectors.accuracy(xTest, yTest)\n",
    "    clf = SVC(kernel='linear')\n",
    "    clf.fit(xTrain, yTrain)\n",
    "    yPred = clf.predict(xTest)\n",
    "    return cost, accuracy, accuracy_score(yTest, yPred)\n",
    "\n",
    "costs = {}\n",
    "accuracies = {}\n",
    "accuraciesSVM = {}\n",
    "\n",
    "for dataset in datasets:\n",
    "    costs[dataset] = []\n",
    "    accuracies[dataset] = []\n",
    "    accuraciesSVM[dataset] = []\n",
    "\n",
    "for i in range(iterations):\n",
    "    print(i,\"th iteration\")\n",
    "    for dataset in datasets:\n",
    "        print(\"Dataset:\",dataset)\n",
    "        cost,accuracy,svmAccuracy = collectTrainData(dataset, True)\n",
    "        costs[dataset].append(cost)\n",
    "        accuracies[dataset].append(accuracy)\n",
    "        accuraciesSVM[dataset].append(svmAccuracy)\n",
    "        print(\"\\n\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    with open('../SimulationResults/costDataset' + dataset+'.csv', 'w', newline='') as csvfile:\n",
    "        avgCosts = {}\n",
    "        length = costs[dataset].__len__()\n",
    "        s = np.array([sum(a) for a in zip(*costs[dataset])])\n",
    "        avgCosts[dataset] = getListsAverage(costs[dataset])\n",
    "        \n",
    "        writer = csv.writer(csvfile, delimiter=',')\n",
    "        writer.writerow(['Iteration'] + [dataset])\n",
    "        combined = [ [i] + [x] for i, x in enumerate(avgCosts[dataset])]\n",
    "        writer.writerows(combined)\n",
    "\n",
    "with open('../SimulationResults/accuracyDataset.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile, delimiter=',')\n",
    "    titleRow = []\n",
    "    dataRow = []\n",
    "    for dataset in datasets:\n",
    "        titleRow.append(dataset)\n",
    "        titleRow.append(dataset + \"SVM\")\n",
    "        dataRow.append(np.mean(accuracies[dataset]))\n",
    "        dataRow.append(np.mean(accuraciesSVM[dataset]))\n",
    "    writer.writerow(titleRow)\n",
    "    writer.writerow(dataRow)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
